# Copy this file to .env for shared defaults and optionally add .env.local for local overrides.
# Load order: .env -> .env.local -> shell environment vars.

APP_NAME=data-ghost-api
APP_ENV=dev
APP_HOST=0.0.0.0
APP_PORT=8000
CORS_ALLOW_ORIGINS=http://localhost:3000,http://localhost:5173
# Optional regex for preview/staging domains, e.g. Vercel:
# CORS_ALLOW_ORIGIN_REGEX=https://.*\\.vercel\\.app

# LLM routing
LLM_PROVIDER=mock
LLM_DEFAULT_MODEL=mock-default
LLM_CHEAP_MODEL=mock-cheap
LLM_EXPENSIVE_MODEL=mock-expensive
LLM_ENABLED=true
LLM_MAX_USD_PER_REQUEST=0.03
LLM_MAX_USD_PER_DAY=2.00
LLM_ESTIMATED_COMPLETION_TOKENS=600

# Anonymous rate limits
ASK_RATE_LIMIT_PER_MINUTE=30
ASK_RATE_LIMIT_PER_HOUR=300
VOICE_RATE_LIMIT_PER_MINUTE=20
VOICE_RATE_LIMIT_PER_HOUR=200

# Ask cache
ASK_CACHE_TTL_SECONDS=600

# Real provider keys (set only if using openai/anthropic)
# OPENAI_API_KEY=sk-...
# ANTHROPIC_API_KEY=...

# OPENAI_STT_MODEL=gpt-4o-mini-transcribe
# ELEVENLABS_API_KEY=...
# ELEVENLABS_VOICE_ID=...
# ELEVENLABS_MODEL_ID=eleven_multilingual_v2
# ELEVENLABS_OUTPUT_FORMAT=mp3_44100_128
# VOICE_MAX_UPLOAD_MB=15
# VOICE_MAX_TTS_CHARS=3000
# VOICE_CACHE_TTL_SECONDS=1800

# Cost estimation knobs (USD per 1k tokens)
LLM_PRICE_PROMPT_PER_1K=0.001
LLM_PRICE_COMPLETION_PER_1K=0.002

# SQL safety budgets
QUERY_TIMEOUT_SECONDS=5.0
QUERY_MAX_ROWS=5000
QUERY_MAX_PER_REQUEST=10

# Upload budgets
DATASET_MAX_UPLOAD_MB=10
CONTEXT_MAX_UPLOAD_MB=10
DATASET_MAX_ROWS=10000
DATASET_MAX_COLUMNS=150

# RAG behavior
RAG_CHUNK_SIZE=800
RAG_CHUNK_OVERLAP=100
RAG_TOP_K=5
